{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgedouzas/avatar-poc/blob/main/environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHfaFppboEJ7"
      },
      "source": [
        "# Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AneDdey8SPaX",
        "outputId": "6eb95fe2-3efb-4fc3-92cc-f6c5db882fbd"
      },
      "outputs": [],
      "source": [
        "# Setup environment\n",
        "!sudo apt-get update\n",
        "!apt install software-properties-common\n",
        "!sudo apt-get install python3.8 python3.8-distutils\n",
        "!curl -sS https://bootstrap.pypa.io/pip/3.8/get-pip.py -o get-pip.py\n",
        "!sudo python3.8 get-pip.py\n",
        "!python3.8 -m pip install -U setuptools wheel\n",
        "!sudo apt-get install python3.9 python3.9-distutils\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!sudo python3.9 get-pip.py\n",
        "!python3.9 -m pip install -U setuptools wheel\n",
        "\n",
        "# Install SadTalker\n",
        "!git clone https://github.com/cedro3/SadTalker.git &> /dev/null\n",
        "%cd SadTalker\n",
        "!export PYTHONPATH=/content/SadTalker:$PYTHONPATH\n",
        "!python3.8 -m pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!apt update\n",
        "!apt install ffmpeg &> /dev/null\n",
        "!python3.8 -m pip install -r requirements.txt\n",
        "!rm -rf checkpoints\n",
        "!bash scripts/download_models.sh\n",
        "\n",
        "# Install piper\n",
        "!python3.9 -m pip install piper-tts\n",
        "!python3.9 -m piper.download_voices en_US-lessac-medium\n",
        "!python3.9 -m piper.download_voices el_GR-rapunzelina-low"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TNYhqWfppOS"
      },
      "source": [
        "# Gradio App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "LMaewM9rpyzC",
        "outputId": "bb99ccdd-6faf-4c01-a121-27ad606c2c8e"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import subprocess\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Language to voice model mapping\n",
        "MODELS_MAPPING = {\n",
        "    'English': 'en_US-lessac-medium',\n",
        "    'Greek': 'el_GR-rapunzelina-low'\n",
        "}\n",
        "\n",
        "def generate_video(language, text, image):\n",
        "\n",
        "    language_model = MODELS_MAPPING.get(language, 'en_US-lessac-medium')\n",
        "\n",
        "    # Set paths\n",
        "    driven_audio_path = 'examples/driven_audio/input_audio.wav'\n",
        "    source_image_path = 'examples/source_image/input_image.png'\n",
        "\n",
        "    # Save uploaded image to source path\n",
        "    shutil.copy(image, source_image_path)\n",
        "\n",
        "    # Run TTS to generate audio\n",
        "    subprocess.run([\n",
        "        'python3.9', '-m', 'piper',\n",
        "        '-m', language_model,\n",
        "        '-f', driven_audio_path,\n",
        "        '--', text\n",
        "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Run inference\n",
        "    subprocess.run([\n",
        "        'python3.8', 'inference.py',\n",
        "        '--driven_audio', driven_audio_path,\n",
        "        '--source_image', source_image_path,\n",
        "        '--result_dir', './results'\n",
        "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Construct expected output filename (latest .mp4 in results/)\n",
        "    result_subdirs = sorted(os.listdir('./results'), reverse=True)\n",
        "    for subdir in result_subdirs:\n",
        "        path = os.path.join('./results', subdir, 'input_image##output.mp4')\n",
        "        if os.path.exists(path):\n",
        "            return path\n",
        "\n",
        "    return \"Error: No output video generated.\"\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Avatar PoC\")\n",
        "\n",
        "    with gr.Row():\n",
        "        language_input = gr.Dropdown(choices=list(MODELS_MAPPING.keys()), label=\"Select Language\", value=\"English\")\n",
        "        text_input = gr.Textbox(lines=4, label=\"Enter Text\")\n",
        "        image_input = gr.Image(label=\"Upload Image\", type=\"filepath\")\n",
        "\n",
        "    generate_button = gr.Button(\"Generate Video\")\n",
        "\n",
        "    video_output = gr.Video(label=\"Generated Video\")\n",
        "\n",
        "    generate_button.click(\n",
        "        fn=generate_video,\n",
        "        inputs=[language_input, text_input, image_input],\n",
        "        outputs=video_output\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "db5031b3636a3f037ea48eb287fd3d023feb9033aefc2a9652a92e470fb0851b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
